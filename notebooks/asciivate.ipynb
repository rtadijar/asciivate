{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This notebook contains code for the implementation and training of a simple linear model, as well as various utility.\n",
    "\"\"\"\n",
    "\n",
    "from math import ceil\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from os.path import getsize\n",
    "import glob\n",
    "from pathlib import Path\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from skimage import data, img_as_float\n",
    "import cv2\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, SubsetRandomSampler\n",
    "\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tileset(fp):\n",
    "    with open(fp, 'rb') as _if:\n",
    "        n_tiles = ord(_if.read(1))\n",
    "        n_rows = ord(_if.read(1))\n",
    "        n_cols = ord(_if.read(1))\n",
    "        \n",
    "        n_pixels = n_rows * n_cols\n",
    "        \n",
    "        tileset = []\n",
    "        \n",
    "        for i in range(n_tiles):\n",
    "            tile = np.frombuffer(_if.read(n_pixels), dtype = np.ubyte)    \n",
    "            tileset.append(tile)\n",
    "        \n",
    "        tileset = np.asarray(tileset)\n",
    "        \n",
    "        return n_rows, n_cols, tileset\n",
    "\n",
    "def get_xy_pairs(fp):\n",
    "    with open(fp, 'rb') as _if:       \n",
    "        \n",
    "        n_rows = np.fromfile(_if, np.int32, 1)[0]\n",
    "        n_cols = np.fromfile(_if, np.int32, 1)[0]\n",
    "        \n",
    "        n_pixels = n_rows * n_cols\n",
    "        \n",
    "        assert( (getsize(fp)-8) % (4*(n_pixels+1)) == 0 )\n",
    "        \n",
    "        n_pairs = int((getsize(fp) - 8) / (4*(n_pixels + 1)))\n",
    "  \n",
    "        xs = []\n",
    "        ys = []\n",
    "        \n",
    "        for i in range(n_pairs):\n",
    "            xs.append(np.fromfile(_if, np.float32, n_pixels))\n",
    "            ys.append(np.fromfile(_if, np.int32, 1))\n",
    "        \n",
    "        return n_rows, n_cols, np.asarray(xs), np.squeeze(np.asarray(ys))\n",
    "\n",
    "def show_pair(x, y):\n",
    "    \n",
    "    plt.figure()\n",
    "    \n",
    "    if x.dtype == np.float32:\n",
    "        x = (x*255).astype(np.ubyte)\n",
    "    if y.dtype == np.float32:\n",
    "        y = (y*255).astype(np.ubyte)\n",
    "    \n",
    "    plt.subplot(121)\n",
    "    plt.imshow(x, cmap='gray', vmin=0, vmax=255)\n",
    "    plt.subplot(122)\n",
    "    plt.imshow(y, cmap='gray', vmin=0, vmax=255)\n",
    "    \n",
    "def show_imgs(imgs, n_cols=4, shape=None):\n",
    "    \n",
    "    plt.figure()\n",
    "    \n",
    "    n = len(imgs)    \n",
    "    n_rows = ceil(n / n_cols)\n",
    "    \n",
    "    for i, img in enumerate(imgs):\n",
    "\n",
    "        code = n_rows*100 + n_cols*10 + i + 1\n",
    "   \n",
    "        plt.subplot(code)        \n",
    "        plt.imshow(img.reshape(shape), cmap='gray', vmin=0, vmax=255)\n",
    "        \n",
    "def get_loaders(xs, ys, batch_size = 64, val_split=.2):  \n",
    "    \n",
    "    if isinstance(xs, np.ndarray):   \n",
    "        xs = torch.from_numpy(xs)\n",
    "    if isinstance(ys, np.ndarray):\n",
    "        ys = torch.from_numpy(ys).float()\n",
    "    \n",
    "    idx = torch.randperm(len(xs))\n",
    "    \n",
    "    xs = xs[idx]\n",
    "    ys = ys[idx]\n",
    "    \n",
    "    dataset = TensorDataset(torch.Tensor(xs), torch.Tensor(ys))\n",
    "    \n",
    "    split = int(np.floor(val_split * len(xs)))\n",
    "    \n",
    "    train_indices, val_indices = idx[split:], idx[:split]\n",
    "    \n",
    "    train_sampler = SubsetRandomSampler(train_indices)\n",
    "    val_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=train_sampler)\n",
    "    val_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=val_sampler)\n",
    "    \n",
    "    return train_loader, val_loader\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(195, 256)\n",
    "        self.fc2 = nn.Linear(256, 256)\n",
    "        self.fc3 = nn.Linear(256, 256)\n",
    "        self.fc4 = nn.Linear(256, 95)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "def get_accuracy(model, loader):\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        num_correct = 0\n",
    "        num_ys = 0\n",
    "        \n",
    "        for i, data in enumerate(loader):\n",
    "            xs, ys = data[0].to(device), data[1].long().to(device)\n",
    "\n",
    "            outputs = model(xs)\n",
    "            \n",
    "            \n",
    "            outputs = torch.argmax(outputs, 1)\n",
    "            \n",
    "            num_correct += sum(outputs == ys)\n",
    "            num_ys += len(ys)\n",
    "            \n",
    "        print(f'Got {num_correct} / {num_ys} with accuracy {float(num_correct)/float(num_ys)*100:.2f}') \n",
    "    \n",
    "    return\n",
    "\n",
    "def get_topk_accuracy(model, loader, k=3):\n",
    "    \n",
    "    num_correct = 0\n",
    "    num_ys = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(loader):\n",
    "            xs, ys = data[0].to(device), data[1].long().to(device)\n",
    "\n",
    "            outputs = model(xs)\n",
    "\n",
    "            outputs = torch.topk(outputs, k)[1]\n",
    "            \n",
    "            for i in range(len(ys)):\n",
    "                if (outputs[i]==ys[i]).any():\n",
    "                    num_correct += 1\n",
    "            \n",
    "            num_ys += len(ys)\n",
    "\n",
    "        print(f'Got {num_correct} / {num_ys} with top-{k} accuracy {float(num_correct)/float(num_ys)*100:.2f}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Training!\"\"\"\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.0005, momentum=0.9)\n",
    "\n",
    "val_losses = []\n",
    "val_max = 3\n",
    "\n",
    "for epoch in range(200):\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        xs, ys = data[0].to(device), data[1].long().to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(xs)\n",
    "        loss = criterion(outputs, ys)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    print('[%d] training loss: %.3f' %\n",
    "          (epoch + 1, running_loss / len(train_loader)))\n",
    "    \n",
    "    if epoch % 5 == 4:\n",
    "\n",
    "        val_loss = 0.0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            \n",
    "            \n",
    "            for i, data in enumerate(val_loader, 0):\n",
    "                xs, ys = data[0].to(device), data[1].long().to(device)\n",
    "\n",
    "                outputs = model(xs)\n",
    "                loss = criterion(outputs, ys)\n",
    "\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                    \n",
    "            print('[%d] total val loss: %.3f' %\n",
    "                  (epoch + 1, val_loss / len(val_loader)))\n",
    "        \n",
    "        torch.save(model, 'model{}.pt'.format(epoch))\n",
    "        \n",
    "  \n",
    "            \n",
    "print('Finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_ascii(img, model, tileset, tile_shape, slice_shape):\n",
    "    \n",
    "    tile_rows, tile_cols = tile_shape\n",
    "    slice_rows, slice_cols = slice_shape\n",
    "    \n",
    "    x_pad = slice_cols - tile_cols\n",
    "    y_pad = slice_rows - tile_rows\n",
    "    \n",
    "    rows = (img.shape[0] - 2*y_pad) // tile_rows\n",
    "    cols = (img.shape[1] - 2*x_pad) // tile_cols\n",
    "\n",
    "    \n",
    "    \n",
    "    ascii_img = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for row in range(rows):\n",
    "            ascii_img.append([])\n",
    "\n",
    "            for col in range(cols):\n",
    "                \n",
    "                patch = img[ tile_rows*row : tile_rows*row + slice_rows, tile_cols*col: tile_cols*col + slice_cols ]\n",
    "                \n",
    "                tile_ind = torch.argmax(model(torch.from_numpy(patch).flatten().float().to(device)))\n",
    "                \n",
    "                \n",
    "                ascii_img[-1].append(tileset[tile_ind].reshape(tile_rows, tile_cols))\n",
    "            \n",
    "            ascii_img[-1] = np.hstack(ascii_img[-1])\n",
    "            \n",
    "\n",
    "    ascii_img = np.vstack(ascii_img)\n",
    "  \n",
    "    return ascii_img\n",
    "\n",
    "def get_indices(img, model, tileset, tile_shape, slice_shape):\n",
    "    \n",
    "    tile_rows, tile_cols = tile_shape\n",
    "    slice_rows, slice_cols = slice_shape\n",
    "    \n",
    "    x_pad = slice_cols - tile_cols\n",
    "    y_pad = slice_rows - tile_rows\n",
    "    \n",
    "    rows = (img.shape[0] - 2*y_pad) // tile_rows\n",
    "    cols = (img.shape[1] - 2*x_pad) // tile_cols\n",
    "\n",
    "    \n",
    "    \n",
    "    indices= []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for row in range(rows):\n",
    "            for col in range(cols):\n",
    "                \n",
    "                patch = img[ tile_rows*row : tile_rows*row + slice_rows, tile_cols*col: tile_cols*col + slice_cols ]\n",
    "                \n",
    "                indices.append(torch.argmax(model(torch.from_numpy(patch).flatten().float().to(device))))\n",
    "\n",
    "            \n",
    "    return indices\n",
    "    \n",
    "\n",
    "def asciivate(fp, process=False):\n",
    "    \n",
    "    img = cv2.imread(fp)\n",
    "    \n",
    "    if img is None:\n",
    "        return\n",
    "\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    if process:\n",
    "\n",
    "        img = cv2.bilateralFilter(img, 7, 400, 400)\n",
    "        img = cv2.Canny(img, 8, 15)\n",
    "        img = cv2.GaussianBlur(img, (3, 3), 0)\n",
    "\n",
    "    img = img_as_float(~img)\n",
    "\n",
    "    ascii_img = convert_to_ascii(img, model, tileset, (tile_rows, tile_cols), (slice_rows, slice_cols))\n",
    "    \n",
    "    return ascii_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_raw_model(fp, model):\n",
    "    with open(fp, 'wb') as _if:\n",
    "        for key, val in model.state_dict().items():\n",
    "\n",
    "            \n",
    "            dims = val.shape\n",
    "            \n",
    "            if len(dims) == 2:\n",
    "                val = val.transpose(0, 1)\n",
    "                dims = val.shape\n",
    "            \n",
    "            print(key)\n",
    "            print(val.shape)          \n",
    "            \n",
    "            if 'weight' in key:\n",
    "                for dim in dims:\n",
    "                    _if.write(int(dim).to_bytes(4, sys.byteorder))\n",
    "                \n",
    "            print(len(val.flatten().numpy().tobytes()))\n",
    "            _if.write(val.flatten().numpy().tobytes())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ascii_env",
   "language": "python",
   "name": "ascii"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
